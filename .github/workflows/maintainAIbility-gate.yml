name: ğŸ¤– maintainAIbility-gate

on:
  push:
    branches: [main, develop] # Only run on push to main/develop (not feature branches)
  pull_request:
    branches: [main] # Run on PRs to main
  workflow_dispatch: # Allow manual triggering for expensive macOS tests
    inputs:
      run_integration_tests:
        description: 'Run expensive Maestro integration tests ($0.08/min)'
        required: false
        default: false
        type: boolean

env:
  EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}

jobs:
  # Foundation Layer - Basic Code Quality (run in parallel)
  format-code:
    name: ğŸ“ Format Code
    runs-on: ubuntu-latest
    timeout-minutes: 3

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ§¹ Install slop-mop
        run: pip3 install -e ./slop-mop --break-system-packages --quiet

      - name: ğŸ¨ Run slop-mop lint & format gate
        run: sm validate --quality-gates javascript:lint-format

  lint-typescript:
    name: ğŸ” Lint (delegated to slop-mop)
    runs-on: ubuntu-latest
    timeout-minutes: 1
    needs: [format-code]
    steps:
      - name: âœ… Covered by slop-mop
        run: echo "Lint and format validated by slop-mop in format-code job"

  # Static Analysis Layer - Depends on clean code
  check-typescript-types:
    name: ğŸ—ï¸ Check TypeScript Types
    runs-on: ubuntu-latest
    timeout-minutes: 4
    needs: [format-code, lint-typescript]

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ—ï¸ Run TypeScript Compiler
        run: pip install -e ./slop-mop --quiet && sm validate --quality-gates javascript:types

  detect-code-duplication:
    name: ğŸ”„ Detect Code Duplication
    runs-on: ubuntu-latest
    timeout-minutes: 3
    needs: [format-code, lint-typescript]

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ§¹ Install slop-mop
        run: pip3 install -e ./slop-mop --break-system-packages --quiet

      - name: ğŸ“‹ Run slop-mop duplication gate
        run: sm validate --quality-gates quality:duplication

  audit-security-vulnerabilities:
    name: ğŸ”’ Audit Security Vulnerabilities
    runs-on: ubuntu-latest
    timeout-minutes: 3

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ”’ Run NPM Security Audit
        run: npm audit --audit-level high
        continue-on-error: true

  # Testing Layer - Depends on static analysis
  run-unit-tests-with-coverage:
    name: ğŸ§ª Run Unit Tests with Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: [check-typescript-types, detect-code-duplication]

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ§¹ Install slop-mop
        run: pip3 install -e ./slop-mop --break-system-packages --quiet

      - name: ğŸ§ª Run slop-mop tests & coverage gates
        run: sm validate --quality-gates javascript:tests javascript:coverage

  # Integration Layer - Depends on unit tests
  run-maestro-integration-tests:
    name: ğŸ­ Run Maestro Integration Tests
    runs-on: macos-latest
    timeout-minutes: 60
    needs: run-unit-tests-with-coverage
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.run_integration_tests == 'true' # Manual trigger only - macOS runners are expensive ($0.08/min)

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ”§ Setup EAS CLI
        uses: expo/expo-github-action@v8
        with:
          eas-version: latest
          token: ${{ secrets.EXPO_TOKEN }}

      - name: ğŸ” Debug Environment
        run: |
          echo "ğŸ” Environment debugging..."
          echo "Node version: $(node --version)"
          echo "NPM version: $(npm --version)"
          echo "PATH: $PATH"
          echo "EAS CLI available: $(command -v eas || echo 'not found')"
          if command -v eas; then
            echo "EAS version: $(eas --version)"
          fi
          echo "EXPO_TOKEN set: ${{ secrets.EXPO_TOKEN != '' }}"

      - name: ğŸ­ Execute Maestro Integration Test Suite
        run: ./scripts/run_integration_tests.sh
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}

      - name: ğŸ“¸ Upload Test Screenshots and Artifacts
        uses: actions/upload-artifact@v4
        if: always() # Always upload artifacts, even on failure
        with:
          name: maestro-test-artifacts
          path: |
            test_artifacts/
            ~/.maestro/tests/
          retention-days: 365
          if-no-files-found: warn

      - name: ğŸ–¼ï¸ Display Test Screenshots in Job Summary
        if: always() # Always run, even on failure
        run: |
          echo "# ğŸ“¸ Test Screenshots and Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Function to convert image to base64 and embed
          embed_image() {
            local image_path="$1"
            local title="$2"
            if [ -f "$image_path" ]; then
              echo "### $title" >> $GITHUB_STEP_SUMMARY
              echo "<details>" >> $GITHUB_STEP_SUMMARY
              echo "<summary>Click to view screenshot</summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "![Screenshot](data:image/png;base64,$(base64 -i "$image_path"))" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi
          }

          # Find and display screenshots from test artifacts
          if [ -d "test_artifacts/ci" ]; then
            echo "## ğŸ” Test Failure Screenshots" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            for screenshot in test_artifacts/ci/*/failure_screenshot.png; do
              if [ -f "$screenshot" ]; then
                test_name=$(basename $(dirname "$screenshot"))
                embed_image "$screenshot" "âŒ Failed Test: $test_name"
              fi
            done
            
            # Display Maestro debug screenshots
            for screenshot in test_artifacts/ci/*/*.png; do
              if [ -f "$screenshot" ] && [[ "$screenshot" != *"failure_screenshot"* ]]; then
                test_name=$(basename $(dirname "$screenshot"))
                screenshot_name=$(basename "$screenshot")
                embed_image "$screenshot" "ğŸ” Debug Screenshot: $test_name - $screenshot_name"
              fi
            done
          fi

          # Find and display screenshots from Maestro debug output
          if [ -d "$HOME/.maestro/tests" ]; then
            echo "## ğŸ­ Maestro Debug Output" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Find today's test runs
            today=$(date +%Y-%m-%d)
            for debug_dir in $HOME/.maestro/tests/*$today*; do
              if [ -d "$debug_dir" ]; then
                echo "### ğŸ“ Debug Session: $(basename "$debug_dir")" >> $GITHUB_STEP_SUMMARY
                echo "" >> $GITHUB_STEP_SUMMARY
                
                # Display all screenshots from this debug session
                for screenshot in "$debug_dir"/*.png; do
                  if [ -f "$screenshot" ]; then
                    screenshot_name=$(basename "$screenshot")
                    embed_image "$screenshot" "ğŸ–¼ï¸ Maestro Debug: $screenshot_name"
                  fi
                done
                
                # Display any log files
                for log_file in "$debug_dir"/*.log; do
                  if [ -f "$log_file" ]; then
                    echo "#### ğŸ“‹ $(basename "$log_file")" >> $GITHUB_STEP_SUMMARY
                    echo "<details>" >> $GITHUB_STEP_SUMMARY
                    echo "<summary>Click to view logs</summary>" >> $GITHUB_STEP_SUMMARY
                    echo "" >> $GITHUB_STEP_SUMMARY
                    echo '```' >> $GITHUB_STEP_SUMMARY
                    head -50 "$log_file" >> $GITHUB_STEP_SUMMARY
                    echo '```' >> $GITHUB_STEP_SUMMARY
                    echo "</details>" >> $GITHUB_STEP_SUMMARY
                    echo "" >> $GITHUB_STEP_SUMMARY
                  fi
                done
              fi
            done
          fi

          # Summary of test results
          echo "## ğŸ“Š Test Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Artifacts Location**: \`test_artifacts/ci/\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Maestro Debug**: \`~/.maestro/tests/\`" >> $GITHUB_STEP_SUMMARY
          echo "- **Screenshots**: Available in job artifacts and embedded above" >> $GITHUB_STEP_SUMMARY

  verify-expo-build-process:
    name: ğŸ”¨ Verify Expo Build Process
    runs-on: ubuntu-latest
    timeout-minutes: 8
    needs: run-unit-tests-with-coverage
    if: github.event_name == 'pull_request' && github.base_ref == 'main'

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ—ï¸ Test Expo Export for iOS and Android
        run: |
          echo "ğŸ” Verifying iOS export..."
          npx expo export --platform ios
          echo "ğŸ” Verifying Android export..."
          npx expo export --platform android
          echo "âœ… Export verification complete"

      - name: ğŸ“± Test EAS Build Configuration
        run: |
          if [ -z "${{ env.EXPO_TOKEN }}" ]; then
            echo "EXPO_TOKEN not available - skipping EAS dry run"
            exit 0
          fi
          npx eas build --platform ios --profile testflight --dry-run
        continue-on-error: true

  # Dependency Analysis - Optional, runs in parallel
  analyze-npm-dependencies:
    name: ğŸ“¦ Analyze NPM Dependencies
    runs-on: ubuntu-latest
    timeout-minutes: 5
    continue-on-error: true
    if: github.event_name == 'pull_request'

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ“¦ Check for Outdated Dependencies
        run: |
          echo "ğŸ” Checking for outdated dependencies..."
          npm outdated || true
          echo "ğŸ” Checking for unused dependencies..."
          npx depcheck || true
        continue-on-error: true

      - name: ğŸ“Š Measure Bundle Size
        run: |
          echo "ğŸ“Š Analyzing bundle size..."
          npx expo export --platform ios
          du -sh dist/ || echo "Bundle analysis complete"
        continue-on-error: true

  # Production Build - Final step, depends on everything critical
  build-for-testflight-production:
    name: ğŸš€ Build for TestFlight Production
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [run-unit-tests-with-coverage, verify-expo-build-process, run-maestro-integration-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
      - name: ğŸ“¥ Checkout
        uses: actions/checkout@v4
        with:
          submodules: true

      - name: ğŸ“¦ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: âš¡ Install dependencies
        run: npm ci --legacy-peer-deps

      - name: ğŸ”§ Setup EAS CLI
        uses: expo/expo-github-action@v8
        with:
          eas-version: latest
          token: ${{ secrets.EXPO_TOKEN }}

      - name: ğŸ” Verify Production Build Configuration
        run: |
          if [ -z "$EXPO_TOKEN" ]; then
            echo "EXPO_TOKEN not available - skipping EAS build verification"
            exit 0
          fi
          echo "ğŸ” Verifying TestFlight build configuration..."
          echo "Note: This only validates configuration - actual build/submission happens in EAS Build workflow"
          eas build --platform ios --profile testflight --dry-run
        env:
          EXPO_TOKEN: ${{ secrets.EXPO_TOKEN }}
